\documentclass[preprint]{sigplanconf}

\usepackage[utf8]{inputenc}
% the following standard packages may be helpful, but are not required
\usepackage{longtable}
%\usepackage{mathtools}
%\usepackage{multicol}
%\usepackage{multirow}
\usepackage{booktabs}
%\usepackage{courier}
%\usepackage[scaled]{helvet}
%\usepackage{url}
\usepackage{listings}
%\usepackage{enumitem}
%\usepackage{mdwlist} % tighter description environment (starred)
%
\usepackage{graphicx}
\usepackage{softdev}
\usepackage{amsmath}
%\usepackage{mdwlist}
%\usepackage{pifont}
\usepackage{xspace}

\newcommand{\kalibera}{Kalibera \& Jones\xspace}
\newcommand{\krun}{Krun\xspace}
\newcommand{\hypone}{H1\xspace}
\newcommand{\hyptwo}{H2\xspace}
\newcommand{\binarytrees}{\emph{binary trees}\xspace}
\newcommand{\richards}{\emph{Richards}\xspace}
\newcommand{\spectralnorm}{\emph{spectralnorm}\xspace}
\newcommand{\nbody}{\emph{n-body}\xspace}
\newcommand{\fasta}{\emph{fasta}\xspace}
\newcommand{\fannkuch}{\emph{fannkuch redux}\xspace}
\newcommand{\bencherthree}{Linux1/i7-4709K\xspace}
\newcommand{\bencherfive}{Linux2/i7-4790\xspace}
\newcommand{\benchersix}{OpenBSD/i7-4790\xspace}
\newcommand{\bencherseven}{ARM\edd{XXX name properly if used}\xspace}

\lstset{
    basicstyle=\tt\scriptsize,
    xleftmargin=2em,
    framexleftmargin=1.5em,
    numberstyle=\scriptsize\tt\color{gray},
    captionpos=b,
    escapeinside={{<!}{!>}},
}

\SDShowCommentTags{default}  %final

\begin{document}

\title{Virtual Machine Warmup Blows Hot and Cold}

\authorinfo{Edd Barrett}
{Software Development Team, Department of Informatics, King's College London}{\texttt{http://eddbarrett.co.uk/}}

\authorinfo{Carl Friedrich Bolz}
{Software Development Team, Department of Informatics, King's College London}{\texttt{http://cfbolz.de/}}

\authorinfo{Rebecca Killick}
{Department of Mathematics and Statistics, University of Lancaster}{\texttt{http://www.lancs.ac.uk/\~{}killick/}}

\authorinfo{Vincent Knight}
{School of Mathematics, Cardiff University}{\texttt{http://vknight.org/}}

\authorinfo{Sarah Mount}
{Software Development Team, Department of Informatics, King's College London}{\texttt{http://snim2.org/}}

\authorinfo{Laurence Tratt}
{Software Development Team, Department of Informatics, King's College London}{\texttt{http://tratt.net/laurie/}}


\maketitle

\section{Introduction}
\label{sec:intro}

Many modern languages are implemented as Virtual Machines (VMs) which use a
Just-In-Time (JIT) compiler to translate `hot' parts of a program into efficient
machine code at run-time. Since it takes time to determine which parts of the
program are hot, and then compile them, programs which are JIT compiled are
said to be subject to a \emph{warmup} phase. The traditional view of
JIT compiled VMs is that program execution is slow during the warmup phase, and
fast afterwards, when \emph{peak performance} is said to have been reached
(see Figure~\ref{fig:trad} for a simplified view of this).
This traditional view underlies most benchmarking of JIT compiled VMs, which
generally aim to measure peak performance.
Typically, benchmarks are run repeatedly in a single process, then data prior
to peak performance is discarded.

The aim of this paper is to test the following hypothesis:
\begin{description}
  \item[\hypone] Small, deterministic programs exhibit traditional warmup behaviour.
\end{description}
In order to test this hypothesis, we present a carefully designed
experiment where a number of simple benchmarks are run on a variety of
VMs for a large number of \emph{in-process iterations} and repeated using fresh
\emph{process executions} (i.e.~each process execution runs multiple in-process
iterations). We deliberately treat VMs as black boxes: we simply run benchmarks
and record timing data.

\begin{figure}[t]
\centering
\includegraphics[width=.5\textwidth]{img/picturebook_warmup}
\caption{The traditional notion of warmup: a program starts slowly executing in
an interpreter; once hot parts of the program are identified, they are
translated by the JIT compiler to machine code; at this point warmup
is said to have completed, and peak performance reached.}
\label{fig:trad}
\end{figure}

While some benchmarks on some VMs run as per
traditional expectations, we found a number of surprising cases. At
the most extreme, some benchmarks never warm up, staying at their initial performance
levels indefinitely and some even slowdown. Of the eight
VMs we looked at, none consistently warmed under the traditional model.

Our results clearly invalidate H1: the traditional view of warmup is no longer
valid. We are not aware that anyone has systematically noted this
problem before, let alone take it into account when benchmarking. This suggests
that many published VM benchmarks (including our own) may have presented
results which are misleading in some situations.

We believe that accurate VM benchmarking is paramount, for both VM authors, and
for many end users. VM authors need to know if optimisations have an effect
distinguishable from noise (and many optimisations have only a small effect).
Similarly, end-users with latency sensitive workloads (e.g. games or other soft
real-time systems) rely upon accurate benchmarking during their evaluation
phase. Our results suggest that current benchmarking methodology is leading
these parties astray.

% XXX needs at-least one
\cite{test123}

\bibliographystyle{plain}
\bibliography{bib}

\end{document}

